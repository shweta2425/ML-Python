{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.717504Z",
     "start_time": "2019-04-16T10:29:06.714289Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas.api.types as ptypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.845857Z",
     "start_time": "2019-04-16T10:29:06.722015Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'classification_2.csv' does not exist: b'classification_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c1f1fa9148a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_original\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classification_2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdf_original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'classification_2.csv' does not exist: b'classification_2.csv'"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "df_original=pd.read_csv(\"classification_2.csv\",delimiter=\",\")\n",
    "\n",
    "df =df_original\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.870929Z",
     "start_time": "2019-04-16T10:29:06.851035Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns=[\n",
    "\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial_Status\",\n",
    "\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_Gain\", \"Capital_Loss\",\n",
    "\"Hours_per_week\", \"Country\", \"Target\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.883788Z",
     "start_time": "2019-04-16T10:29:06.875966Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.923557Z",
     "start_time": "2019-04-16T10:29:06.888916Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[\"Target\"] = df[\"Target\"].map({ \" <=50K\":0, \" >50K\":1 })\n",
    "df['Target'].replace(' <=50K',0,inplace=True)\n",
    "df['Target'].replace(' >50K',1,inplace=True)\n",
    "\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.932376Z",
     "start_time": "2019-04-16T10:29:06.928596Z"
    }
   },
   "outputs": [],
   "source": [
    "# read file and rename columns\n",
    "# df_original = pd.read_csv(\n",
    "# \"classification_2.csv\",\n",
    "# names=[\n",
    "# \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial_Status\",\n",
    "# \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_Gain\", \"Capital_Loss\",\n",
    "# \"Hours_per_week\", \"Country\", \"Target\"])\n",
    "# df =df_original\n",
    "# df['newtarget'] = 0\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.945226Z",
     "start_time": "2019-04-16T10:29:06.935530Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(df['Target'])):\n",
    "#     if df['Target'][i] == ' >50K':\n",
    "#         df['newtarget'][i] = 0\n",
    "#     else:\n",
    "#         df['newtarget'][i] = 1\n",
    "# df['newtarget'].head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.965642Z",
     "start_time": "2019-04-16T10:29:06.946982Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:06.998747Z",
     "start_time": "2019-04-16T10:29:06.969625Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.036746Z",
     "start_time": "2019-04-16T10:29:07.003796Z"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.100963Z",
     "start_time": "2019-04-16T10:29:07.041932Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=False,inplace=True) \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.133192Z",
     "start_time": "2019-04-16T10:29:07.106158Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.188038Z",
     "start_time": "2019-04-16T10:29:07.138410Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.211606Z",
     "start_time": "2019-04-16T10:29:07.193210Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.222519Z",
     "start_time": "2019-04-16T10:29:07.216694Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.247053Z",
     "start_time": "2019-04-16T10:29:07.224218Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.255393Z",
     "start_time": "2019-04-16T10:29:07.252179Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df,columns=['Workclass','Education','Martial_Status','Occupation','Relationship','Race','Sex','Country'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.485407Z",
     "start_time": "2019-04-16T10:29:07.257613Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sb.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.547782Z",
     "start_time": "2019-04-16T10:29:07.490687Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dummy variables whose are in categorical type\n",
    "# for name in df.columns:\n",
    "#    if df[name].dtype != \"int64\":\n",
    "#        df[name] = pd.get_dummies(df[name]) \n",
    "# df = pd.get_dummies(df, columns=[\n",
    "#     \"Workclass\", \"Education\", \"Martial_Status\", \"Occupation\", \"Relationship\",\n",
    "#     \"Race\", \"Sex\", \"Country\"\n",
    "# ])\n",
    "# df = pd.get_dummies(df,columns=[\n",
    "#     'Workclass','Education','Martial_Status','Occupation','Relationship','Race','Sex','Country'])\n",
    "df = pd.get_dummies(df)\n",
    "df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.573656Z",
     "start_time": "2019-04-16T10:29:07.552950Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.585276Z",
     "start_time": "2019-04-16T10:29:07.578865Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.598327Z",
     "start_time": "2019-04-16T10:29:07.586998Z"
    }
   },
   "outputs": [],
   "source": [
    "print(corr['Target'].sort_values(ascending=False)[:]) #top 15 values\n",
    "print('----------------------')\n",
    "print(corr['Target'].sort_values(ascending=False)[-5:]) #last 5 values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.609608Z",
     "start_time": "2019-04-16T10:29:07.600346Z"
    }
   },
   "outputs": [],
   "source": [
    "corr['Target'].sort_values(ascending=False)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.621640Z",
     "start_time": "2019-04-16T10:29:07.611345Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.749961Z",
     "start_time": "2019-04-16T10:29:07.623345Z"
    }
   },
   "outputs": [],
   "source": [
    "sb.countplot(x='Target',data=df,palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.759636Z",
     "start_time": "2019-04-16T10:29:07.755124Z"
    }
   },
   "outputs": [],
   "source": [
    "def Feature_Scaling(df):\n",
    "        for column in df.columns:\n",
    "            df[column] = ((df[column] - df[column].min()) /\n",
    "                             (df[column].max() - df[column].min()))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:07.995651Z",
     "start_time": "2019-04-16T10:29:07.763677Z"
    }
   },
   "outputs": [],
   "source": [
    "df = Feature_Scaling(df)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:08.005946Z",
     "start_time": "2019-04-16T10:29:08.001433Z"
    }
   },
   "outputs": [],
   "source": [
    "def Split(data):\n",
    "    train_set=0.70*len(data)\n",
    "    train=int(train_set)\n",
    "#         print(train)\n",
    "    test_set=0.30*len(data)\n",
    "    test=int(test_set)\n",
    "        \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:08.017452Z",
     "start_time": "2019-04-16T10:29:08.011205Z"
    }
   },
   "outputs": [],
   "source": [
    " train,test = Split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:08.054689Z",
     "start_time": "2019-04-16T10:29:08.019332Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data=df.tail(train)\n",
    "test_data=df.head(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:08.079868Z",
     "start_time": "2019-04-16T10:29:08.060565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separating the output and the parameters data frame\n",
    "def separate(df):\n",
    "    output = df.Target\n",
    "    return df.drop('Target', axis=1), output\n",
    "\n",
    "x_data_train,y_data_train = separate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:08.091623Z",
     "start_time": "2019-04-16T10:29:08.085620Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data_test,y_data_test=separate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:29:26.839681Z",
     "start_time": "2019-04-16T10:29:08.097033Z"
    }
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self):\n",
    "        # loads csv file\n",
    "        self.alpha = 0.029\n",
    "        self.epoch = 10550\n",
    "        \n",
    "    def Gradient_Descent(self, train_x_data, train_y_data,theta_vector):\n",
    "#         print(theta_vector.shape,train_x_data.shape)\n",
    "        for length in range(self.epoch):\n",
    "            z=np.dot(theta_vector.T,train_x_data.T) \n",
    "            sigmoid=(1 / (1 + np.exp(-z))) \n",
    "            a=sigmoid - train_y_data.T  \n",
    "            temp=np.dot(a,train_x_data)  \n",
    "            temp=np.divide(np.dot(self.alpha,temp),len(train_x_data))\n",
    "            theta = theta_vector - temp.T\n",
    "        return theta\n",
    "    \n",
    "    def Test_data(self, test_x_data, theta_vector): \n",
    "#         print(\"sgd\",test_x_data.shape, theta_vector.shape)\n",
    "        z=np.dot(theta_vector.T,test_x_data.T)\n",
    "        sigmoid=np.array(1 / (1 + np.exp(-z)))  \n",
    "#         print(sigmoid.shape)\n",
    "        \n",
    "        y_prediction = np.zeros((test_x_data.shape[0], 1), dtype=float)\n",
    "        \n",
    "        for i in range(0,len(sigmoid)):\n",
    "            if round(sigmoid[i][0], 2) <= 0.5:\n",
    "                y_prediction[i][0] = 0\n",
    "            else:\n",
    "                y_prediction[i][0] = 1\n",
    "        return y_prediction\n",
    "    \n",
    "  \n",
    "            \n",
    "    def Accuracy(self,y_predict,y_test_data):\n",
    "        count=0\n",
    "#         print(y_test_data.shape,y_predict.shape)\n",
    "        for i in range(0,len(y_test_data)):\n",
    "            if y_predict[i]==y_test_data[i]:\n",
    "                count+=1\n",
    "#         print(\"cnt\",count)\n",
    "        count=(count/len(y_test_data)*100)\n",
    "        \n",
    "#         print(\"accuracy of test data\",(count/len(y_test_data))*100)\n",
    "        return count\n",
    "    \n",
    "def main():\n",
    "    obj = Logistic_Regression()\n",
    "    # calling method by class object\n",
    "    x_train_data = np.array(x_data_train)\n",
    "    y_train_data = np.array(y_data_train)\n",
    "    \n",
    "    y_train_data = y_train_data.reshape(len(y_train_data),1)\n",
    " \n",
    "    print(\"x_train_data\",x_train_data.shape)\n",
    "    print(\"y_train_data\",y_train_data.shape)    \n",
    "    \n",
    "    x_test_data = np.array(x_data_test)\n",
    "    y_test_data = np.array(y_data_test) \n",
    "    y_test_data = y_test_data.reshape(len(y_test_data),1)\n",
    "    \n",
    "    print(\"x_test_data\",x_test_data.shape)\n",
    "    print(\"y_test_data\",y_test_data.shape)    \n",
    "    \n",
    "    x_train_data = np.column_stack((np.ones((x_train_data.shape[0], 1)), x_train_data))\n",
    "    print(\"x_train_data\",x_train_data.shape)\n",
    "    \n",
    "    x_test_data = np.column_stack((np.ones((x_test_data.shape[0], 1)), x_test_data))\n",
    "    print(\"x_test_data\",x_test_data.shape)\n",
    "\n",
    "    x_size = 108\n",
    "    \n",
    "#     theta_vector = np.ones(((x_size + 1), 1), dtype='f')\n",
    "    theta_vector = np.full((x_size+1,1),.1)\n",
    "    print(\"theta_vector\",theta_vector.shape)\n",
    "    \n",
    "    theta_vector = obj.Gradient_Descent(x_train_data, y_train_data,theta_vector)\n",
    "    print(\"theta afr\",theta_vector.shape)\n",
    "#     print(theta_vector)\n",
    "\n",
    "    y_predict_test = obj.Test_data(x_test_data, theta_vector)    \n",
    "    y_predict_train = obj.Test_data(x_train_data, theta_vector)\n",
    "    \n",
    "#     print(\"suhgd\",y_predict_train)\n",
    "    \n",
    "    acc_train=obj.Accuracy(y_predict_train,y_train_data)\n",
    "    print(\"accuracy of train data=\",acc_train)\n",
    "    \n",
    "    acc_test=obj.Accuracy(y_predict_test,y_test_data)\n",
    "    print(\"accuracy of test data=\",acc_test)\n",
    "    \n",
    "    \n",
    "#     print(y_predict.shape)\n",
    "#     acc = obj.accuracy(y_test_data, y_predict,y_predict_train,y_train_data)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
